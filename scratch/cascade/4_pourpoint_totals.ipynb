{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pour Point Totals\n",
    "By Cascade Tuholske 2020.02.02\n",
    "\n",
    "Merge effluent watershed totals with pour points for plume models. This is based off Jared's original Rmd code.\n",
    "\n",
    "**BE SURE TO CHECK N AND FIO FILE NAMES AND PATHS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depedencies\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File names and dirs ... update for N and FIO as needed\n",
    "data_type = 'N'\n",
    "data = 'N_open'\n",
    "data_out =  \"/home/cascade/projects/wastewater/data/interim/\"+data_type+\"_effluent_output/\" #update as needed\n",
    "data_dir = \"/home/cascade/projects/wastewater/data/interim/\"\n",
    "watersheds_fn = 'effluent_'+data+'_watersheds.shp'\n",
    "pourpoints_fn = 'pour_points/global_plume_2007_2010.shp'\n",
    "final_fn = 'effluent_'+data+'_pourpoints.shp' ## UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basin_id</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>au_09807</td>\n",
       "      <td>POINT (158.913015963685 -54.64636307400065)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>au_09806</td>\n",
       "      <td>POINT (158.9214017251773 -54.61009196102273)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>au_09805</td>\n",
       "      <td>POINT (158.8775040159086 -54.55366988325454)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>au_09804</td>\n",
       "      <td>POINT (77.53563120865223 -38.71234259192368)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>au_09803</td>\n",
       "      <td>POINT (77.5536642440721 -37.78617552055444)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   basin_id                                      geometry\n",
       "0  au_09807   POINT (158.913015963685 -54.64636307400065)\n",
       "1  au_09806  POINT (158.9214017251773 -54.61009196102273)\n",
       "2  au_09805  POINT (158.8775040159086 -54.55366988325454)\n",
       "3  au_09804  POINT (77.53563120865223 -38.71234259192368)\n",
       "4  au_09803   POINT (77.5536642440721 -37.78617552055444)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load orginal pour points (run twice for some reason)\n",
    "pourpoints = gpd.read_file(data_dir+pourpoints_fn) # are in epsg: 54009\n",
    "pourpoints = pourpoints.to_crs({'init': 'epsg:4326'}) # switch crs\n",
    "pourpoints.drop(['SUM_FERTC','SUM_PESTC', 'SUM_IMPV'], axis= 1, inplace = True)\n",
    "pourpoints.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basin_id</th>\n",
       "      <th>effluent</th>\n",
       "      <th>count</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>au_01136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>23.135643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>au_01148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39</td>\n",
       "      <td>39.661102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>au_01149</td>\n",
       "      <td>4433864.0</td>\n",
       "      <td>15</td>\n",
       "      <td>14.872913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>au_01150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>16.525459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>au_01151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>34.703464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   basin_id   effluent  count       area\n",
       "0  au_01136        0.0     25  23.135643\n",
       "1  au_01148        0.0     39  39.661102\n",
       "2  au_01149  4433864.0     15  14.872913\n",
       "3  au_01150        0.0     16  16.525459\n",
       "4  au_01151        0.0     35  34.703464"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load watersheds\n",
    "watersheds = gpd.read_file(data_out+watersheds_fn) # are in epsg: 54009\n",
    "watersheds = watersheds[['basin_id', 'effluent', 'count', 'area']] # get cols\n",
    "watersheds.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "print('h20',len(watersheds), 'pp', len(pourpoints))\n",
    "merge = pd.merge(watersheds, pourpoints, on = 'basin_id', how = 'inner') # <<--- one gets dropped\n",
    "final = gpd.GeoDataFrame(merge)\n",
    "final.crs = {'init' :'epsg:4326'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CPT 2020.03.23 -- keep all data for now\n",
    "\n",
    "# Drop zeros\n",
    "# print(len(final))\n",
    "# final = final[final['effluent'] >0]\n",
    "# print(len(final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "final.to_file(data_out+final_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save out subset of 500 for plume testing \n",
    "#final[:500].to_file(data_out+'effluent_'+data_nm+'_pourpoints_500.shp') #### UPDATE FILE NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make top 75 pour points for FIO & N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nm = 'N'\n",
    "data_in =  \"/Users/cascade/Github/wastewater_ohi/data/processed/\"+data_nm+\"_effluent_output/\" #update as needed\n",
    "data_out = '/Users/cascade/Github/wastewater_ohi/data/processed/OK_FinalReport/'\n",
    "data = gpd.read_file(data_in+'effluent_'+data_nm+'_pourpoints.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(by = 'effluent', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make 100\n",
    "rank = list(range(1, 101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rank'] = rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(data_out+'effluent_'+data_nm+'_pourpoints_top100.csv')\n",
    "data.to_file(data_out+'effluent_'+data_nm+'_pourpoints_top100.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to remove inland pour points by rank to get top 75\n",
    "# Going to remove these inland pour points from the top 100 for FIO and then save out the top 75\n",
    "\n",
    "#inlandFIO100 = [14, 76, 94, 16, 44, 47, 49, 22, 91, 19, 20, 40, 73, 78, 79, 25]\n",
    "inlandN100 = [29,11,52,83,28,76,41,45,93,79,63,16,35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = inlandN100\n",
    "data75 = data[~data['rank'].isin(remove)]\n",
    "print(len(data75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data75 = data75.sort_values(by = 'effluent', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data75.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = range(1,len(data75)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data75['rank'] = rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data75 = data75[:75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data75.to_csv(data_out+'effluent_'+data_nm+'_pourpoints_top75.csv')\n",
    "data75.to_file(data_out+'effluent_'+data_nm+'_pourpoints_top75.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataN25 = data75[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pct of total \n",
    "\n",
    "dataN25['effluent'].sum()/gpd.read_file(data_in+'effluent_'+data_nm+'_pourpoints.shp')['effluent'].sum() *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get old watershed names and add to current\n",
    "\n",
    "old = pd.read_csv('/Users/cascade/Github/wastewater_ohi/data/processed/preopen1km/OK_FinalReport/N/effluent_N_pourpoints_top25.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = old[['country', 'name', 'basin_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataN25 = dataN25.merge(old, on = 'basin_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataN25.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataN25.to_csv(data_out+'effluent_'+data_nm+'_pourpoints_top25.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare our N to Total N \n",
    "\n",
    "- 48 TG N Y-1 in 2006 from `Riverine nitrogen export from the continents to the coasts`\n",
    "- 46 TG N Y-1 in 2005 from `Exploring changes in river nitrogen export to the world's oceans`\n",
    "- 164 TG N Y-1 in 2017 for total ocean all sources from `A reevaluation of the magnitude and impacts of anthropogenic atmospheric nitrogen inputs on the ocean\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File names and dirs ... update for N and FIO as needed\n",
    "data_nm = 'N'\n",
    "data_out =  \"/Users/cascade/Github/wastewater_ohi/data/processed/\"+data_nm+\"_effluent_output/\" #update as needed\n",
    "N_fn = 'effluent_'+data_nm+'_pourpoints.shp' ## UPDATE\n",
    "N = gpd.read_file(data_out+N_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasum = N['effluent'].sum()\n",
    "datasum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('pct in rivers to ocean ', datasum / 10**12 / 48 * 100)\n",
    "print('pct in rivers to ocean ', datasum / 10**12 / 46 * 100)\n",
    "print('pct total N to ocean ', datasum / 10**12 / 164 * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top75_fn = '/Users/cascade/Github/wastewater_ohi/data/processed/OK_FinalReport/effluent_N_pourpoints_top75.shp'\n",
    "top75 = gpd.read_file(top75_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top25 = top75[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top25['effluent'].sum() / datasum * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare vs In situ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insituN = gpd.read_file('/Users/cascade/Github/wastewater_ohi/data/interim/benchmarking_N_with_percentages.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insituN.to_csv('/Users/cascade/Github/wastewater_ohi/data/interim/benchmarking_N_with_percentages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load old table from OK report\n",
    "old_fn = '/Users/cascade/Github/wastewater_ohi/data/processed/OK_FinalReport/Select_N_BenchMark_old.csv'\n",
    "old = pd.read_csv(old_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insituN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename congo river\n",
    "insituN = insituN.replace({'basin_name': 'Zaire'}, 'Congo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data to merge\n",
    "out = pd.DataFrame()\n",
    "out['Country'] = old['Country']\n",
    "out['basin_name'] = old['basin_name']\n",
    "\n",
    "select = pd.DataFrame()\n",
    "select['dn_tot'] = insituN['dn_tot'] \n",
    "select['our_n'] = insituN['our_n']\n",
    "select['percent'] = insituN['percent']\n",
    "select['basin_name'] = insituN['basin_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.merge(select, on = 'basin_name', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.sort_values(['Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out new table for OK report\n",
    "new_fn = '/Users/cascade/Github/wastewater_ohi/data/processed/OK_FinalReport/Select_N_BenchMark.csv'\n",
    "out.to_csv(new_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.DataFrame()\n",
    "names['basin_id'] = ['basin_id'][:25]\n",
    "names['country'] = FIO['Country'][:25]\n",
    "names['name'] = FIO['Name'][:25]\n",
    "dataN25 = data75[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insituN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Zambezi'\n",
    "insituN[insituN['basin_name']==name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check\n",
    "na_76192 seems to throw an error at 567 pourpoints when running on the whole list. I have no clue why it is exiting the routine.\n",
    "\n",
    "Wait the last file logged is na_09706\n",
    "\n",
    "Ok so the maxdist in `plume_buffer.py` created by the exp is, I think, the max number of cells the effluent can travel based on the logscale effluent total, but I think our smallest effluent values are too small so we need to update these exp in the `plume_buffer.py` routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = gpd.read_file(data_out+'effluent_N_pourpoints.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(check['effluent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = check[check['basin_id']=='na_09705']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error.to_file('/Users/cascade/Desktop/errorpp-ai_10576.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(check[check['effluent']>100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check[:600].tail(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check FIO and N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIO_fn = '/Users/cascade/Github/wastewater_ohi/data/processed/hold20200212/effluent_FIO_pourpoints.shp'\n",
    "FIO = gpd.read_file(FIO_fn)\n",
    "\n",
    "FIO_fn_check = '/Users/cascade/Github/wastewater_ohi/data/processed/FIO_effluent_output/effluent_FIO_pourpoints.shp'\n",
    "FIO_check = gpd.read_file(FIO_fn_check)\n",
    "\n",
    "\n",
    "N_fn = '/Users/cascade/Github/wastewater_ohi/data/processed/hold20200212/effluent_N_pourpoints.shp'\n",
    "N = gpd.read_file(N_fn)\n",
    "\n",
    "N_fn_check = '/Users/cascade/Github/wastewater_ohi/data/processed/N_effluent_output/effluent_N_pourpoints.shp'\n",
    "N_check = gpd.read_file(N_fn_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIO.sort_values(['effluent'], ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIO_check.sort_values(['effluent'], ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N.sort_values(['effluent'], ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_check.sort_values(['effluent'], ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
